{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montrons que $E[R_n(\\^\\theta)]=E_{\\epsilon}[\\frac{1}{n} ||(I_n - X(X^TX)^{-1}X^T)\\epsilon||^2_2]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sait que dans le setting de l'OLS, le risque empirique s'écrit : $R_n(\\theta) = \\frac{1}{n}||y-X\\theta||^2_2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sait également que l'estimateur OLS qui minimise le risque empirique est $\\^\\theta = (X^TX)^{-1}X^Ty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Déterminons d'abord $R_n(\\^\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "R_n(\\^\\theta)&=\\frac{1}{n}||y-X\\^\\theta||^2_2 \\\\\n",
    "&= \\frac{1}{n} ||y - X(X^TX)^{-1}X^Ty||^2_2 \\\\\n",
    "&=\\frac{1}{n} ||(I_n - X(X^TX)^{-1}X^T)y||^2_2\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que $X(X^TX)^{-1}X^T$ est la matrice de projection orthogonale de $y$ sur l'espace engendré par les colonnes de la matrice design $X$, ces colonnes correspondent aux différentes caractéristiques de l'espace d'entrée. ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or on sait que $||v||_2 = \\sqrt{v_1^2 + v_2^2 + \\ldots + v_n^2} = \\sqrt{v^T v} $. Et donc, on a donc $||v||_2^2=v^T v$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "R_n(\\^\\theta) &=\\frac{1}{n} ((I_n - X(X^TX)^{-1}X^T)y)^T((I_n - X(X^TX)^{-1}X^T)y)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notons $P = (I_n - X(X^TX)^{-1}X^T)$. Cette matrice permet d'avoir les résidus, c'est-à-dire les parties de $y$ non expliquées par les caractéristiques de $X$. On obtient alors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "R_n(\\^\\theta) &=\\frac{1}{n} (Py)^T(Py)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, on assume que dans le modèle linéaire $y = X\\theta^*+\\epsilon$. On a alors:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "Py &= P(X\\theta^* + \\epsilon) \\\\\n",
    "&=PX\\theta^* + P\\epsilon\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or $PX\\theta^* = 0$ car $X\\theta^*$ est une combinaison linéaire des caractéristiques de X et n'a donc pas de résidu. On obtient donc: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "Py&=P\\epsilon\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En remplaçant dans la formule du risque empirique, on a:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "E[R_n(\\^\\theta)] &=E_\\epsilon[\\frac{1}{n} (P\\epsilon)^T(P\\epsilon)] \\\\\n",
    " &=E_\\epsilon[\\frac{1}{n} ((I_n - X(X^TX)^{-1}X^T)\\epsilon)^T((I_n - X(X^TX)^{-1}X^T)\\epsilon)] \\\\\n",
    " &=E_\\epsilon[\\frac{1}{n} ||(I_n - X(X^TX)^{-1}X^T)\\epsilon||^2_2]  \n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soit $A \\in \\mathbb{R}^{n,n}$. Montrons que $\\sum\\limits_{(i,j) \\in [1,n]^2} A^2_{ij} = \\operatorname{tr}(A^T A)$. Par définition de la trace, on a:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{tr}(A^TA) &= \\sum\\limits_{i \\in [1,n]} (A^TA)_{ii} \\\\\n",
    "&= \\sum\\limits_{i \\in [1,n]} \\sum\\limits_{j \\in [1,n]} (A^T)_{ij} A_{ji} \\\\\n",
    "&= \\sum\\limits_{i \\in [1,n]} \\sum\\limits_{j \\in [1,n]} A_{ji} A_{ji} \\\\\n",
    "&= \\sum\\limits_{(i,j) \\in [1,n]^2} A_{ji}^2 \\\\\n",
    "&= \\sum\\limits_{(i,j) \\in [1,n]^2} A_{ij}^2\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montrons que $E_\\epsilon[\\frac{1}{n}||A\\epsilon||^2_2]=\\frac{\\sigma^2}{n}\\operatorname{tr}(A^TA)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "E_\\epsilon[\\frac{1}{n}||A\\epsilon||^2_2] &= \\frac{1}{n} E_\\epsilon[||A\\epsilon||^2_2] \\\\\n",
    "&= \\frac{1}{n}E_\\epsilon[(A\\epsilon)^T(A\\epsilon)] \\\\\n",
    "&= \\frac{1}{n}E_\\epsilon[\\epsilon^TA^TA\\epsilon] \\\\\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or on sait que si $x \\in \\mathbb{R}$ alors $\\operatorname{tr}(x) = x$. Or $\\epsilon^TA^TA\\epsilon$ est un scalaire (vis à vis des dimensions de $\\epsilon$ et $A$ et du résultats de ces produits)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "E_\\epsilon[\\frac{1}{n}||A\\epsilon||^2_2] &= \\frac{1}{n}E_\\epsilon[\\operatorname{tr}(\\epsilon^TA^TA\\epsilon)] \\\\\n",
    "&= \\frac{1}{n}E_\\epsilon[\\operatorname{tr}(A\\epsilon\\epsilon^TA^T)] \\quad \\text{car} \\operatorname{tr}(AB)=\\operatorname{tr}(BA) \\\\\n",
    "&= \\frac{1}{n}\\operatorname{tr}(E_\\epsilon[A\\epsilon\\epsilon^TA^T]) \\quad \\text{par linéarité de } \\operatorname{tr} \\text{et } E \\\\\n",
    "&= \\frac{1}{n}\\operatorname{tr}(AE_\\epsilon[\\epsilon\\epsilon^T]A^T)\n",
    "\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sait que $\\epsilon$ est un vecteur gaussien centré (ce qui veut dire que $E_\\epsilon(\\epsilon) =0$) dont la matrice de variance est $\\sigma^2I_n$.\n",
    "Par définition on sait également que :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\Sigma &= E[(\\epsilon - E_\\epsilon(\\epsilon))(\\epsilon - E_\\epsilon(\\epsilon))^T] \\\\\n",
    "&= E[\\epsilon\\epsilon^T] \\\\\n",
    "\\sigma^2I_n &= E[\\epsilon\\epsilon^T]\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "E_\\epsilon[\\frac{1}{n}||A\\epsilon||^2_2] &= \\frac{1}{n}\\operatorname{tr}(A\\sigma^2I_nA^T) \\\\\n",
    "&= \\frac{\\sigma^2}{n}\\operatorname{tr}(AA^T) \\\\\n",
    "&= \\frac{\\sigma^2}{n}\\operatorname{tr}(A^TA) \\quad \\text{car} \\operatorname{tr}(AB)=\\operatorname{tr}(BA) \\\\\n",
    "\\end{aligned}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
